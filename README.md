# ğŸ©º Prescription Chatbot (RAG + MCP + Ollama)

A local **Retrieval-Augmented Generation (RAG) chatbot** that answers questions from **medical prescription PDFs**.  
Built with **FAISS** (for vector search), **Sentence-Transformers** (for embeddings), and **Ollama MCP models** (local LLMs).

âš ï¸ **Disclaimer**: This is for educational purposes only. Not a substitute for professional medical advice.

---

## ğŸš€ Features
- Preprocess PDFs once into FAISS index
- Local embeddings (no API costs)
- Local LLM inference with Ollama (`phi3:mini` recommended for low RAM)
- FastAPI backend with Swagger UI (`/docs`)
- Streamlit frontend for chat
- Source citations with expandable chunks

---

## ğŸ“‚ Project Structure
rag_mcp_app/
â”‚â”€â”€ app.py # FastAPI backend
â”‚â”€â”€ retriever.py # FAISS retriever
â”‚â”€â”€ ingestion.py # PDF processing
â”‚â”€â”€ preprocess.py # Build FAISS index from PDFs
â”‚â”€â”€ ollama_mcp.py # Ollama interface
â”‚â”€â”€ ui.py # Streamlit chat UI
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ pdfs/ # Store PDFs here
â”‚ â”œâ”€â”€ index.faiss # Vector index (after preprocessing)
â”‚ â”œâ”€â”€ meta.pkl # Metadata (after preprocessing)